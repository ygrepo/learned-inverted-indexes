{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import itertools\n",
    "from itertools import accumulate\n",
    "from IPython import display\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as torch_data\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.insert(0, \"../src\")\n",
    "from collection import Collection\n",
    "\n",
    "BASE_DIR = os.path.abspath('')\n",
    "\n",
    "import torch.nn.functional as f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Params\n",
    "posting_length_to_use = 128\n",
    "\n",
    "scaling_factor=30\n",
    "\n",
    "# Fix this\n",
    "learning_rate = 1e-3\n",
    "lambda_l2 = 1e-5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_tensor_type(torch.DoubleTensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zigzag_encode (i):\n",
    "    return (i >> 31) ^ (i << 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch_data.Dataset):\n",
    "    def __init__(self, data_list, pos_list):\n",
    "        self.data = data_list\n",
    "        self.target = pos_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index], self.target[index]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "deltas_list = []\n",
    "global_max = 0\n",
    "\n",
    "\n",
    "# Load data\n",
    "test_collection = Collection(\"../test_data/test_collection\")\n",
    "for term_id, pl in enumerate(test_collection):\n",
    "    p = pl[0]\n",
    "    term_len = len(p)\n",
    "    if len(p) >= posting_length_to_use:\n",
    "        model = nn.Sequential(\n",
    "            nn.Linear(term_len, int(term_len/scaling_factor)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(term_len/scaling_factor), term_len)\n",
    "        )\n",
    "        model.to(device)\n",
    "\n",
    "#         criterion = torch.nn.L1Loss()\n",
    "        criterion = torch.nn.MSELoss()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=lambda_l2) # built-in L2\n",
    "#         optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) # built-in L2\n",
    "\n",
    "        X = np.arange(term_len).astype(np.double)\n",
    "        X = torch.arange(term_len, dtype=torch.double).to(device)\n",
    "        y = p.astype(np.double)\n",
    "        y = torch.tensor(y, dtype=torch.float64).to(device)\n",
    "        for t in itertools.count():\n",
    "            y_pred = model(X)\n",
    "            loss = criterion(y_pred,y)\n",
    "            print(\"[TERM]: %i, [TERM_LEN]: %i, [EPOCH]: %i, [LOSS]: %.6f\" % (term_id, term_len, t, loss.item()))\n",
    "            if loss < 0.001 or t > 10000:\n",
    "                deltas = y_pred.detach().numpy().astype(int) - y.numpy().astype(int)\n",
    "                print(deltas)\n",
    "                delta_zigzag = [len(deltas)] + list(accumulate([zigzag_encode(int(i))+1 for i in deltas]))            \n",
    "                global_max = max(delta_zigzag[-1], global_max)\n",
    "                deltas_list.append(np.array(delta_zigzag, dtype=np.uint32))\n",
    "#                 print(deltas)\n",
    "#                 print(max(deltas/y))\n",
    "#                 print(y)\n",
    "#                 print(y_pred)\n",
    "                plt.plot(np.arange(y_pred.size(0)), pl[0], label=\"Ground truth\")\n",
    "                plt.plot(np.arange(y_pred.size(0)), y_pred.cpu().detach().numpy(), label=\"Predictions\")\n",
    "                plt.xlabel(\"Posting list Index\")\n",
    "                plt.ylabel(\"Doc id\")\n",
    "                plt.title(\"Predicted vs. Ground truth Doc IDs\")\n",
    "                plt.legend(loc=\"best\")\n",
    "                plt.show()\n",
    "#             if (loss < 2):\n",
    "#                 print(y_pred.detach().numpy().astype(int).tolist())\n",
    "#                 print(y.numpy().astype(int).tolist())\n",
    "#                 print(np.count_nonzero(deltas))\n",
    "                print(\"[TERM]: %i, [TERM_LEN]: %i, [EPOCH]: %i, [LOSS]: %.6f\" % (term_id, term_len, t, loss.item()))\n",
    "#                 deltas+=1\n",
    "#                 print(list(accumulate([zigzag_encode(int(i)) for i in deltas])))\n",
    "                break\n",
    "#             display.clear_output(wait=True)\n",
    "    \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if len(deltas_list) > 1:\n",
    "                break\n",
    "\n",
    "            \n",
    "global_max_list = [1, global_max]            \n",
    "deltas_array = np.concatenate([np.array(global_max_list, dtype=np.uint32)] + deltas_list).ravel()\n",
    "DELTA_DIR = os.path.join(BASE_DIR, \"../deltas\")\n",
    "delta_file = os.path.join(DELTA_DIR, \"{}.docs\".format(\"NN\"))\n",
    "print(\"Saving deltas to: {}\".format(delta_file))\n",
    "with open(delta_file, \"wb\") as binfile:\n",
    "    deltas_array.tofile(binfile)\n",
    "\n",
    "freqs_file = os.path.join(DELTA_DIR, \"{}.freqs\".format(\"NN\"))\n",
    "print(\"Saving freqs to: {}\".format(freqs_file))\n",
    "with open(freqs_file, \"wb\") as binfile:\n",
    "    deltas_array[1:-1].tofile(binfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_max_list = [1, global_max]            \n",
    "deltas_array = np.concatenate([np.array(global_max_list, dtype=np.uint32)] + deltas_list).ravel()\n",
    "DELTA_DIR = os.path.join(BASE_DIR, \"../deltas\")\n",
    "delta_file = os.path.join(DELTA_DIR, \"{}.docs\".format(\"NN\"))\n",
    "print(\"Saving deltas to: {}\".format(delta_file))\n",
    "with open(delta_file, \"wb\") as binfile:\n",
    "    deltas_array.tofile(binfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs_file = os.path.join(DELTA_DIR, \"{}.freqs\".format(\"NN\"))\n",
    "print(\"Saving freqs to: {}\".format(freqs_file))\n",
    "with open(freqs_file, \"wb\") as binfile:\n",
    "    deltas_array[1:-1].tofile(binfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_list = []\n",
    "orig_max = 0\n",
    "\n",
    "for term_id, pl in enumerate(test_collection):\n",
    "    p = pl[0]\n",
    "    term_len = len(p)\n",
    "    if len(p) >= posting_length_to_use:\n",
    "        orig_max = max(p[-1], orig_max)\n",
    "        orig_list.append(np.append( np.array([len(p)], dtype=np.uint32),  np.array(p, dtype=np.uint32)))\n",
    "    if len(orig_list) > 1:\n",
    "            break\n",
    "\n",
    "orig_max_list = [1, orig_max]            \n",
    "orig_array = np.concatenate([np.array(orig_max_list, dtype=np.uint32)] + orig_list).ravel()\n",
    "DELTA_DIR = os.path.join(BASE_DIR, \"../deltas\")\n",
    "orig_file = os.path.join(DELTA_DIR, \"{}.docs\".format(\"orig\"))\n",
    "print(\"Saving orig to: {}\".format(orig_file))\n",
    "with open(orig_file, \"wb\") as binfile:\n",
    "    orig_array.tofile(binfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
